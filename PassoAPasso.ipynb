{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Processamento e Análise de Imagens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações utilizadas no trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output as cls\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Model \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import GlobalAvgPool2D as GAP, Dense, Dropout\n",
    "\n",
    "# Callbacks \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Pre-Trained Model\n",
    "from tensorflow.keras.applications import ResNet50V2 as ResNet50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando Local das Imagens de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlimgtreinoD = []\n",
    "urlimgtesteD = []\n",
    "urlimgtreinoE = []\n",
    "urlimgtesteE = []\n",
    "urlimgtreinoF = []\n",
    "urlimgtesteF = []\n",
    "urlimgtreinoG = []\n",
    "urlimgtesteG = []\n",
    "# Diretório contendo as imagens de mamografia\n",
    "raiz = 'S:/Desktop/PAI-github/mamografias/'\n",
    "diretoriototal = os.listdir(raiz)\n",
    "\n",
    "for diretorios in diretoriototal:\n",
    "    caminhodiretorio = raiz + diretorios\n",
    "    # Separar as imagens para treinamento e teste & Criar diretorio de teste e treino\n",
    "    imagens = os.listdir(caminhodiretorio)\n",
    "    if(diretorios[0] == 'D'):\n",
    "        for img in imagens:\n",
    "            if (int(img.split('(')[-1].split(')')[0]) % 4 == 0):\n",
    "                urlimgtesteD.append(caminhodiretorio + '/' + img)\n",
    "            else:\n",
    "                urlimgtreinoD.append(caminhodiretorio + '/' + img)\n",
    "    if(diretorios[0] == 'E'):\n",
    "        for img in imagens:\n",
    "            if (int(img.split('(')[-1].split(')')[0]) % 4 == 0):\n",
    "                urlimgtesteE.append(caminhodiretorio + '/' + img)\n",
    "            else:\n",
    "                urlimgtreinoE.append(caminhodiretorio + '/' + img) \n",
    "    if(diretorios[0] == 'F'):\n",
    "        for img in imagens:\n",
    "            if (int(img.split('(')[-1].split(')')[0]) % 4 == 0):\n",
    "                urlimgtesteF.append(caminhodiretorio + '/' + img)\n",
    "            else:\n",
    "                urlimgtreinoF.append(caminhodiretorio + '/' + img)\n",
    "    if(diretorios[0] == 'G'):\n",
    "        for img in imagens:\n",
    "            if (int(img.split('(')[-1].split(')')[0]) % 4 == 0):\n",
    "                urlimgtesteG.append(caminhodiretorio + '/' + img)\n",
    "            else:\n",
    "                urlimgtreinoG.append(caminhodiretorio + '/' + img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento para a classificação de 4 classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentação, ampliação e separação da base de dados de 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_mammary_region(image):\n",
    "    # Aplicar limiarização adaptativa para segmentar a região da mama\n",
    "    _, thresholded = cv2.threshold(\n",
    "        image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Encontrar os contornos dos objetos na imagem binarizada\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Encontrar o contorno da mama (maior área)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Criar uma máscara em branco do tamanho da imagem\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Desenhar o contorno da mama na máscara\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Criar uma nova imagem apenas com a região da mama\n",
    "    result_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return result_image\n",
    "\n",
    "\n",
    "classes = [\"D\", \"E\", \"F\", \"G\"]\n",
    "for element in classes:\n",
    "    # Definir o caminho completo para o diretório de destino\n",
    "    namedir = \"Test_Data\"\n",
    "    if not os.path.exists(namedir):\n",
    "        # Criar a pasta\n",
    "        os.makedirs(namedir)\n",
    "    place = namedir + \"/\" + element\n",
    "    if not os.path.exists(place):\n",
    "        os.makedirs(place)\n",
    "\n",
    "    diretorio_teste = os.getcwd() + \"/\" + place\n",
    "\n",
    "    if element == \"D\":\n",
    "        for imgurl in urlimgtesteD:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"E\":\n",
    "        for imgurl in urlimgtesteE:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"F\":\n",
    "        for imgurl in urlimgtesteF:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"G\":\n",
    "        for imgurl in urlimgtesteG:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "\n",
    "for element in classes:\n",
    "    # Definir o caminho completo para o diretório de destino\n",
    "    namedir = \"Train_Data\"\n",
    "    if not os.path.exists(namedir):\n",
    "        # Criar a pasta\n",
    "        os.makedirs(namedir)\n",
    "    place = namedir + \"/\" + element\n",
    "    if not os.path.exists(place):\n",
    "        os.makedirs(place)\n",
    "\n",
    "    diretorio_treino = os.getcwd() + \"/\" + place\n",
    "    if element == \"D\":\n",
    "        for imgurl in urlimgtreinoD:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"E\":\n",
    "        for imgurl in urlimgtreinoE:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"F\":\n",
    "        for imgurl in urlimgtreinoF:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"G\":\n",
    "        for imgurl in urlimgtreinoG:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados de teste e de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11328 images belonging to 4 classes.\n",
      "Found 1248 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Generator\n",
    "train_path = 'S:\\Desktop\\PAI-github\\PAI\\Train_Data'\n",
    "test_path = 'S:\\Desktop\\PAI-github\\PAI\\Test_Data'\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Load Data\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    train_path, class_mode='binary', target_size=(256, 256), shuffle=True, batch_size=32)\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    test_path, class_mode='binary', target_size=(256, 256), shuffle=True, batch_size=32)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento da rede neural - 4 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10332/3440820413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/GPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m## Pre-Trained Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50V2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    ## Pre-Trained Model \n",
    "    base_model = ResNet50(input_shape=(256,256,3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "    cls()\n",
    "\n",
    "    # Model Architecture\n",
    "    name = \"ResNet50\"\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GAP(),\n",
    "        Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
    "        Dropout(0.2),\n",
    "        Dense(4, activation='softmax')\n",
    "    ], name=name)\n",
    "\n",
    "    # Callbacks\n",
    "    cbs = [EarlyStopping(patience=3, restore_best_weights=True), ModelCheckpoint(name + \".h5\", save_best_only=True)]\n",
    "\n",
    "    # Model \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=2e-3)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Model Training\n",
    "    history = model.fit(train_ds, validation_data=test_ds, callbacks=cbs, epochs=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura do modelo utilizado e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 8, 8, 2048)        23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,090,372\n",
      "Trainable params: 525,572\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('S:/Desktop/PAI-github/PAI/Resnet50.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 58s 1s/step - loss: 0.7869 - accuracy: 0.6603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7869039177894592, 0.6602563858032227]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento para a classificação de binária"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentação, ampliação e separação da base de dados binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smili\\AppData\\Local\\Temp/ipykernel_15160/2573466361.py:96: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
      "C:\\Users\\smili\\AppData\\Local\\Temp/ipykernel_15160/2573466361.py:116: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
      "C:\\Users\\smili\\AppData\\Local\\Temp/ipykernel_15160/2573466361.py:136: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
      "C:\\Users\\smili\\AppData\\Local\\Temp/ipykernel_15160/2573466361.py:156: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n"
     ]
    }
   ],
   "source": [
    "def segment_mammary_region(image):\n",
    "    # Aplicar limiarização adaptativa para segmentar a região da mama\n",
    "    _, thresholded = cv2.threshold(\n",
    "        image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Encontrar os contornos dos objetos na imagem binarizada\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Encontrar o contorno da mama (maior área)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Criar uma máscara em branco do tamanho da imagem\n",
    "    mask = np.zeros_like(image)\n",
    "\n",
    "    # Desenhar o contorno da mama na máscara\n",
    "    cv2.drawContours(mask, [largest_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Criar uma nova imagem apenas com a região da mama\n",
    "    result_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return result_image\n",
    "\n",
    "\n",
    "classes = [\"I\", \"II\"]\n",
    "for element in classes:\n",
    "    # Definir o caminho completo para o diretório de destino\n",
    "    namedir = \"Test_DataBinary\"\n",
    "    if not os.path.exists(namedir):\n",
    "        # Criar a pasta\n",
    "        os.makedirs(namedir)\n",
    "    place = namedir + \"/\" + element\n",
    "    if not os.path.exists(place):\n",
    "        os.makedirs(place)\n",
    "\n",
    "    diretorio_teste = os.getcwd() + \"/\" + place\n",
    "\n",
    "    if element == \"I\":\n",
    "        for imgurl in urlimgtesteD:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"I\":\n",
    "        for imgurl in urlimgtesteE:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"II\":\n",
    "        for imgurl in urlimgtesteF:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "    if element == \"II\":\n",
    "        for imgurl in urlimgtesteG:\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_teste + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "\n",
    "for element in classes:\n",
    "    # Definir o caminho completo para o diretório de destino\n",
    "    namedir = \"Train_DataBinary\"\n",
    "    if not os.path.exists(namedir):\n",
    "        # Criar a pasta\n",
    "        os.makedirs(namedir)\n",
    "    place = namedir + \"/\" + element\n",
    "    if not os.path.exists(place):\n",
    "        os.makedirs(place)\n",
    "\n",
    "    diretorio_treino = os.getcwd() + \"/\" + place\n",
    "    if element == \"I\":\n",
    "        for imgurl in urlimgtreinoD:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"I\":\n",
    "        for imgurl in urlimgtreinoE:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"II\":\n",
    "        for imgurl in urlimgtreinoF:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n",
    "    if element == \"II\":\n",
    "        for imgurl in urlimgtreinoG:\n",
    "            # Copiar imagens para a nova pasta com a mascara aplicada\n",
    "            imagem = cv2.imread(imgurl, cv2.IMREAD_GRAYSCALE)\n",
    "            segmented_image = segment_mammary_region(imagem)\n",
    "            fileName = imgurl.split(\"/\")\n",
    "            caminho_destino = diretorio_treino + '/' + fileName[-1]\n",
    "            cv2.imwrite(caminho_destino, segmented_image)\n",
    "\n",
    "            # Criar uma copia com a imagem equalizada\n",
    "            caminho_destino_equalizada = diretorio_treino + '/equalizada_' + fileName[-1]\n",
    "            imagem = cv2.imread(caminho_destino, 0)\n",
    "            imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "            cv2.imwrite(caminho_destino_equalizada, imagem_equalizada)\n",
    "\n",
    "            # Criar uma copia com a imagem espelhada\n",
    "            imagem = Image.open(caminho_destino)\n",
    "            imagem_espelhada = imagem.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            caminho_destino = diretorio_treino + '/espelhada_' + fileName[-1]\n",
    "            imagem_espelhada.save(caminho_destino)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados de teste e de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11328 images belonging to 2 classes.\n",
      "Found 1248 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Generator\n",
    "trainbinary_path = 'S:\\Desktop\\PAI-github\\PAI\\Train_DataBinary'\n",
    "testbinary_path = 'S:\\Desktop\\PAI-github\\PAI\\Test_DataBinary'\n",
    "\n",
    "trainbinary_gen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "testbinary_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Load Data\n",
    "train_ds = trainbinary_gen.flow_from_directory(\n",
    "    trainbinary_path, class_mode='binary', target_size=(256, 256), shuffle=True, batch_size=32)\n",
    "test_ds = testbinary_gen.flow_from_directory(\n",
    "    testbinary_path, class_mode='binary', target_size=(256, 256), shuffle=True, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento da rede neural - binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    ## Pre-Trained Model \n",
    "    base_model = ResNet50(input_shape=(256,256,3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "    cls()\n",
    "\n",
    "    # Model Architecture\n",
    "    name = \"ResNet50Binary\"\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GAP(),\n",
    "        Dense(256, activation='relu', kernel_initializer='he_normal'),\n",
    "        Dropout(0.2),\n",
    "        Dense(4, activation='softmax')\n",
    "    ], name=name)\n",
    "\n",
    "    # Callbacks\n",
    "    cbs = [EarlyStopping(patience=3, restore_best_weights=True), ModelCheckpoint(name + \".h5\", save_best_only=True)]\n",
    "\n",
    "    # Model \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=2e-3)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # Model Training\n",
    "    history = model.fit(train_ds, validation_data=test_ds, callbacks=cbs, epochs=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "A classe referente é D\n"
     ]
    }
   ],
   "source": [
    "# Class Names\n",
    "classes = [\"D\", \"E\", \"F\", \"G\"]\n",
    "# Carrega a imagem e redimensiona\n",
    "img = image.load_img('processImage.png', target_size=(256, 256, 3))\n",
    "\n",
    "# Normaliza a imagem\n",
    "img_array = image.img_to_array(img)\n",
    "img_array /= 255.\n",
    "\n",
    "# Cria um objeto EagerTensor a partir da imagem normalizada\n",
    "img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
    "\n",
    "# Adiciona uma dimensão extra para o modelo\n",
    "img_tensor = tf.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "# Carrega o modelo\n",
    "model = load_model('ResNet50.h5')\n",
    "\n",
    "# Faz a predição na imagem\n",
    "predictions = model.predict(img_tensor)\n",
    "\n",
    "# Converte a saída para um rótulo de texto\n",
    "predicted_label = classes[np.argmax(predictions)]\n",
    "\n",
    "# Exibe a classe prevista\n",
    "result = \"A classe referente é \" + predicted_label\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
